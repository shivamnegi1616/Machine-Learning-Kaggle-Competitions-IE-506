{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/23m1508/.conda/envs/shivam_env/lib/python3.12/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /home/23m1508/.conda/envs/shivam_env/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/23m1508/.conda/envs/shivam_env/lib/python3.12/site-packages (from xgboost) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_matrix = []\n",
    "\n",
    "main_class = [100, 200, 300, 400]\n",
    "sub_class = [101, 102, 103, 104, 105, 109, 110, 115, 119, 120, 121, 122, 123, 127, 128, 130, 131, 133, 199, 235, 236, 238, 241, 245, 248, 252, 254, 258, 259, 299, 361, 399, 401, 494, 495, 496, 499]\n",
    "\n",
    "with open('IE506_2024_progchallenge_train.txt', 'r') as file:\n",
    "\n",
    "    for i,line in enumerate(file):\n",
    "        line_list = line.split(\" \")\n",
    "\n",
    "        M = line_list[0]\n",
    "        S = line_list[1]\n",
    "\n",
    "        # Extract numerical values using regular expressions\n",
    "        M = re.findall(r'\\d+', M)\n",
    "        S = re.findall(r'\\d+', S)\n",
    "\n",
    "        # Convert the extracted numbers to integers\n",
    "        M = [int(num) for num in M]\n",
    "        S  = [int(num) for num in S]\n",
    "\n",
    "        main_class_vec = [1 if label in M else 0 for label in main_class]\n",
    "        sub_class_vec = [1 if label in S else 0 for label in sub_class]\n",
    "\n",
    "        # Concatenate main class and subclass vectors\n",
    "        class_vector = main_class_vec + sub_class_vec\n",
    "        \n",
    "        # Append the class vector to the class matrix\n",
    "        class_matrix.append(class_vector)\n",
    "\n",
    "y_matrix = np.array(class_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 41)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the feature-value pairs\n",
    "data = []\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "\n",
    "# Read the data file and populate the data list\n",
    "with open('IE506_2024_progchallenge_train.txt', 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        line_parts = line.split(\" \")\n",
    "        for pair in line_parts[2:]:\n",
    "            feature_id, feature_value = pair.split(':')\n",
    "            row_indices.append(i)\n",
    "            col_indices.append(int(feature_id))\n",
    "            data.append(float(feature_value))\n",
    "\n",
    "# Create a sparse matrix from the collected data\n",
    "sparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(200000, 47236))\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sparse_matrix, y_matrix, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 47236)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'gamma': 0,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost classifier with specified parameters\n",
    "xgb_classifier = XGBClassifier(**params)\n",
    "\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open('xgb_classifier_model2.pkl', 'wb') as file:\n",
    "    pickle.dump(xgb_classifier, file)\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open('xgb_classifier_model2.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    " \n",
    "# Initialize a dictionary of keys (DOK) matrix\n",
    "X_test_final = dok_matrix((150000, 47236), dtype=np.float32)\n",
    " \n",
    "with open('IE506_2024_progchallenge_test.txt', 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        line_list = line.split(\" \")\n",
    "        for s in line_list:\n",
    "            id_, val = s.split(':')\n",
    "            id_ = int(id_)\n",
    "            val = float(val)\n",
    "            X_test_final[i, id_] = val\n",
    "\n",
    "X_test = X_test_final.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 47236)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open('xgb_classifier_model2.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 41)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = [100, 200, 300, 400, 101, 102, 103, 104, 105, 109, 110, 115, 119, 120, 121, 122, 123, 127, 128, 130, 131, 133, 199, 235, 236, 238, 241, 245, 248, 252, 254, 258, 259, 299, 361, 399, 401, 494, 495, 496, 499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = []\n",
    "M = []\n",
    "S = []\n",
    "\n",
    "for i in range(150000):\n",
    "    ID.append(i)\n",
    "    temp_M = []\n",
    "    temp_S = []\n",
    "    for j in range(41):\n",
    "        if 0 <= j <= 3:\n",
    "            if y_pred[i,j] == 1:\n",
    "                temp_M.append(str(cls[j]))\n",
    "\n",
    "        elif 4 <= j :\n",
    "            if y_pred[i,j] == 1:\n",
    "                temp_S.append(str(cls[j]))\n",
    "\n",
    "    M.append(temp_M)\n",
    "    S.append(temp_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'ID' : ID,\n",
    "                    'M' : M,\n",
    "                    'S' : S})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>M</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[100, 300]</td>\n",
       "      <td>[399]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[400]</td>\n",
       "      <td>[495, 496]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID           M           S\n",
       "0   0       [100]       [105]\n",
       "1   1       [100]       [105]\n",
       "2   2  [100, 300]       [399]\n",
       "3   3       [400]  [495, 496]\n",
       "4   4          []          []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved csv file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = \"submission\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "filename = os.path.join(directory, f\"sub56.csv\")\n",
    "df.to_csv(filename, index=False)\n",
    "print('Saved csv file')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shivam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
